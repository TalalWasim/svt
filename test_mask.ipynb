{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8bb9fd9-914f-428e-be72-18d2742729c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_aux_token_vit\n",
    "from utils.parser import parse_args, load_config\n",
    "from torch.utils.data import default_collate\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cd4244a-2d21-498e-81fb-2a26f0d6c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    \"\"\"\n",
    "    Parse the following arguments for a default parser for PySlowFast users.\n",
    "    Args:\n",
    "        shard_id (int): shard id for the current machine. Starts from 0 to\n",
    "            num_shards - 1. If single machine is used, then set shard id to 0.\n",
    "        num_shards (int): number of shards using by the job.\n",
    "        init_method (str): initialization method to launch the job with multiple\n",
    "            devices. Options includes TCP or shared file-system for\n",
    "            initialization. details can be find in\n",
    "            https://pytorch.org/docs/stable/distributed.html#tcp-initialization\n",
    "        cfg (str): path to the config file.\n",
    "        opts (argument): provide addtional options from the command line, it\n",
    "            overwrites the config loaded from file.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Provide SlowFast video training and testing pipeline.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--shard_id\",\n",
    "        help=\"The shard id of current node, Starts from 0 to num_shards - 1\",\n",
    "        default=0,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_shards\",\n",
    "        help=\"Number of shards using by the job\",\n",
    "        default=1,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--init_method\",\n",
    "        help=\"Initialization method, includes TCP or shared file-system\",\n",
    "        default=\"tcp://localhost:9999\",\n",
    "        type=str,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--cfg\",\n",
    "        dest=\"cfg_file\",\n",
    "        help=\"Path to the config file\",\n",
    "        default=\"configs/Kinetics/SLOWFAST_4x16_R50.yaml\",\n",
    "        type=str,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"opts\",\n",
    "        help=\"See slowfast/config/defaults.py for all options\",\n",
    "        default=None,\n",
    "        nargs=argparse.REMAINDER,\n",
    "    )\n",
    "    if len(sys.argv) == 1:\n",
    "        parser.print_help()\n",
    "    return parser.parse_args([])\n",
    "\n",
    "\n",
    "class TubeMaskingGenerator:\n",
    "    def __init__(self, input_size, mask_ratio):\n",
    "        self.frames, self.height, self.width = input_size\n",
    "        self.num_patches_per_frame =  self.height * self.width\n",
    "        self.total_patches = self.frames * self.num_patches_per_frame \n",
    "        self.num_masks_per_frame = int(mask_ratio * self.num_patches_per_frame)\n",
    "        self.total_masks = self.frames * self.num_masks_per_frame\n",
    "\n",
    "    def __repr__(self):\n",
    "        repr_str = \"Masks: total patches {}, mask patches {}\".format(\n",
    "            self.total_patches, self.total_masks\n",
    "        )\n",
    "        return repr_str\n",
    "\n",
    "    def __call__(self):\n",
    "        mask_per_frame = np.hstack([\n",
    "            np.zeros(self.num_patches_per_frame - self.num_masks_per_frame),\n",
    "            np.ones(self.num_masks_per_frame),\n",
    "        ])\n",
    "        np.random.shuffle(mask_per_frame)\n",
    "        mask = np.tile(mask_per_frame, (self.frames,1)).flatten()\n",
    "        return mask\n",
    "\n",
    "\n",
    "def get_sinusoid_encoding_table(n_position, d_hid): \n",
    "    ''' Sinusoid position encoding table ''' \n",
    "    # TODO: make it with torch instead of numpy \n",
    "    def get_position_angle_vec(position): \n",
    "        return [position / np.power(10000, 2 * (hid_j // 2) / d_hid) for hid_j in range(d_hid)] \n",
    "\n",
    "    sinusoid_table = np.array([get_position_angle_vec(pos_i) for pos_i in range(n_position)]) \n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2]) # dim 2i \n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2]) # dim 2i+1 \n",
    "\n",
    "    return torch.FloatTensor(sinusoid_table).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c27a4b07-2558-4d9b-81f4-75df66cdf97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 2\n",
    "C = 768\n",
    "num_tokens = 1568\n",
    "img_size = 224\n",
    "patch_size = 16\n",
    "num_patches = img_size//patch_size\n",
    "frames = 8\n",
    "masker = TubeMaskingGenerator((frames,num_patches,num_patches), 0.8)\n",
    "\n",
    "batch = []\n",
    "for i in range(B):\n",
    "    batch.append(((torch.randn(3,8,224,224)), torch.from_numpy(masker()).to(torch.bool)))\n",
    "\n",
    "batch = default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c062cd88-7459-44e7-9617-ae5842571385",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = batch[0]\n",
    "mask = batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7741f6b-4402-44ed-bb69-5a4dc2c088af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = './models/configs/Kinetics/TimeSformer_divST_8x32_224.yaml'\n",
    "opt = parse_args()\n",
    "opt.cfg_file = cfg\n",
    "config = load_config(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4c5cb3b-0e87-4113-ab18-6d991434bdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model inside with msg: _IncompatibleKeys(missing_keys=['time_embed', 'aux_cls_token', 'blocks.0.temporal_fc.weight', 'blocks.0.temporal_fc.bias', 'blocks.1.temporal_fc.weight', 'blocks.1.temporal_fc.bias', 'blocks.2.temporal_fc.weight', 'blocks.2.temporal_fc.bias', 'blocks.3.temporal_fc.weight', 'blocks.3.temporal_fc.bias', 'blocks.4.temporal_fc.weight', 'blocks.4.temporal_fc.bias', 'blocks.5.temporal_fc.weight', 'blocks.5.temporal_fc.bias', 'blocks.6.temporal_fc.weight', 'blocks.6.temporal_fc.bias', 'blocks.7.temporal_fc.weight', 'blocks.7.temporal_fc.bias', 'blocks.8.temporal_fc.weight', 'blocks.8.temporal_fc.bias', 'blocks.9.temporal_fc.weight', 'blocks.9.temporal_fc.bias', 'blocks.10.temporal_fc.weight', 'blocks.10.temporal_fc.bias', 'blocks.11.temporal_fc.weight', 'blocks.11.temporal_fc.bias', 'head.weight', 'head.bias'], unexpected_keys=[])\n"
     ]
    }
   ],
   "source": [
    "model = get_aux_token_vit(cfg=config, no_head=True)\n",
    "training = False\n",
    "model.training=training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "810c2a4e-0f63-4702-9763-e2b6831d00d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "this one\n",
      "starting\n"
     ]
    }
   ],
   "source": [
    "out = model(video, use_head=False)\n",
    "feat = model.forward_features(video, get_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bcd9687-b238-44a3-81d2-7ae2c14901fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training is: False\n",
      "returns tensor of shape: torch.Size([2, 1536])\n",
      "feature shape: torch.Size([2, 1570, 768])\n"
     ]
    }
   ],
   "source": [
    "if isinstance(out, tuple) == True:\n",
    "    print('training is:', training)\n",
    "    print('returns tuple of length', len(out))\n",
    "    print('shape at 0:', out[0].shape)\n",
    "    print('shape at 1:', out[1].shape)\n",
    "else:\n",
    "    print('training is:', training)\n",
    "    print('returns tensor of shape:', out.shape)\n",
    "\n",
    "print('feature shape:',feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50f14ba2-5e5c-4cab-b661-2ddcbe7e874d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape: torch.Size([2, 1568])\n",
      "expaned pos embed shape: torch.Size([2, 1568, 768])\n"
     ]
    }
   ],
   "source": [
    "pos_embed = get_sinusoid_encoding_table(num_tokens, C)\n",
    "expand_pos_embed = pos_embed.expand(B, -1, -1).type_as(video).to(video.device).clone().detach()\n",
    "print('mask shape:',mask.shape)\n",
    "print('expaned pos embed shape:',expand_pos_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fabe9908-8258-400c-8b5f-2884d593cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_emd_vis = expand_pos_embed[~mask].reshape(B, -1, C)\n",
    "pos_emd_mask = expand_pos_embed[mask].reshape(B, -1, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14fb7565-7a23-4ecb-bcaf-3a2a8fcd76f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 320, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_emd_vis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a064822-9d8c-4e30-b5e0-48350462ea4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "320/8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa75490-d17e-4740-a258-e69f209f704f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
