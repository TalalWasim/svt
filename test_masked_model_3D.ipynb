{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8bb9fd9-914f-428e-be72-18d2742729c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_masked_vit_base_patch16_224\n",
    "from models import get_masked_vit_base_patch16_224_no_decoder\n",
    "from utils.parser import parse_args, load_config\n",
    "from torch.utils.data import default_collate\n",
    "from einops import rearrange\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cd4244a-2d21-498e-81fb-2a26f0d6c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    \"\"\"\n",
    "    Parse the following arguments for a default parser for PySlowFast users.\n",
    "    Args:\n",
    "        shard_id (int): shard id for the current machine. Starts from 0 to\n",
    "            num_shards - 1. If single machine is used, then set shard id to 0.\n",
    "        num_shards (int): number of shards using by the job.\n",
    "        init_method (str): initialization method to launch the job with multiple\n",
    "            devices. Options includes TCP or shared file-system for\n",
    "            initialization. details can be find in\n",
    "            https://pytorch.org/docs/stable/distributed.html#tcp-initialization\n",
    "        cfg (str): path to the config file.\n",
    "        opts (argument): provide addtional options from the command line, it\n",
    "            overwrites the config loaded from file.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Provide SlowFast video training and testing pipeline.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--shard_id\",\n",
    "        help=\"The shard id of current node, Starts from 0 to num_shards - 1\",\n",
    "        default=0,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_shards\",\n",
    "        help=\"Number of shards using by the job\",\n",
    "        default=1,\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--init_method\",\n",
    "        help=\"Initialization method, includes TCP or shared file-system\",\n",
    "        default=\"tcp://localhost:9999\",\n",
    "        type=str,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--cfg\",\n",
    "        dest=\"cfg_file\",\n",
    "        help=\"Path to the config file\",\n",
    "        default=\"configs/Kinetics/SLOWFAST_4x16_R50.yaml\",\n",
    "        type=str,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"opts\",\n",
    "        help=\"See slowfast/config/defaults.py for all options\",\n",
    "        default=None,\n",
    "        nargs=argparse.REMAINDER,\n",
    "    )\n",
    "    if len(sys.argv) == 1:\n",
    "        parser.print_help()\n",
    "    return parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7741f6b-4402-44ed-bb69-5a4dc2c088af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = './models/configs/Kinetics/TimeSformer_divST_8x32_224.yaml'\n",
    "opt = parse_args()\n",
    "opt.cfg_file = cfg\n",
    "config = load_config(opt)\n",
    "# config.TIMESFORMER.PRETRAINED_MODEL = './../pretrained/enc_mae_dec_vmae.pth'\n",
    "config.MODEL.TUBELET_SIZE=2\n",
    "config.MODEL.NUM_FRAMES=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4c5cb3b-0e87-4113-ab18-6d991434bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_masked_vit_base_patch16_224(cfg=config, no_head=True, no_mask=False)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c27a4b07-2558-4d9b-81f4-75df66cdf97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1568\n"
     ]
    }
   ],
   "source": [
    "B = 2\n",
    "C = 768\n",
    "img_size = 224\n",
    "patch_size = 16\n",
    "frames = config.MODEL.NUM_FRAMES\n",
    "tubelet_size = config.MODEL.TUBELET_SIZE\n",
    "num_tokens = (img_size//patch_size)*(img_size//patch_size)*(frames//tubelet_size)\n",
    "\n",
    "batch = []\n",
    "for i in range(B):\n",
    "    batch.append(torch.randn(3,frames,img_size,img_size))\n",
    "\n",
    "batch = default_collate(batch)\n",
    "video = batch\n",
    "print(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e76901a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video torch.Size([2, 3, 16, 224, 224])\n",
      "videos_patch torch.Size([2, 1568, 1536])\n"
     ]
    }
   ],
   "source": [
    "print('video', video.shape)\n",
    "videos_patch = rearrange(video, 'b c (t p0) (h p1) (w p2) -> b (t h w) (p0 p1 p2 c)', p0=tubelet_size, p1=patch_size, p2=patch_size)\n",
    "print('videos_patch',videos_patch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "810c2a4e-0f63-4702-9763-e2b6831d00d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = video.to(device)\n",
    "out = model(video, mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f5305c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label torch.Size([2, 976, 1536])\n"
     ]
    }
   ],
   "source": [
    "B_v, _, C_v = videos_patch.shape\n",
    "label = videos_patch[out[2]].reshape(B_v, -1, C_v)\n",
    "print('label', label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bcd9687-b238-44a3-81d2-7ae2c14901fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuple of length: 3\n",
      "torch.Size([2, 768])\n",
      "torch.Size([2, 976, 1536])\n",
      "torch.Size([2, 1568])\n"
     ]
    }
   ],
   "source": [
    "if isinstance(out, tuple) == True:\n",
    "    print('Tuple of length:', len(out))\n",
    "    for i in range(len(out)):\n",
    "        print(out[i].shape)\n",
    "else:\n",
    "    print('returns tensor of shape:', out.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('svt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4add7a80eb16f4df710800981c38ec9659b7cad49b36fec7ba58dffcbe1cf391"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
